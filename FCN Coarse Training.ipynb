{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from voc_data_reader import VOCDataReader\n",
    "from fcn import FCN\n",
    "import cv2, os, sys\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug('')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINVAL_ROOT_DIR = '/home/paperspace/PASCAL-VOC-Dataset/TrainVal'\n",
    "TEST_ROOT_DIR = '/home/paperspace/PASCAL-VOC-Dataset/Test'\n",
    "VGG_PARAMS_ROOT_DIR = '/home/paperspace/FCN/vgg-weights'\n",
    "\n",
    "fcn = FCN(TRAINVAL_ROOT_DIR, TEST_ROOT_DIR, VGG_PARAMS_ROOT_DIR)\n",
    "dsr = VOCDataReader(TRAINVAL_ROOT_DIR, TEST_ROOT_DIR)\n",
    "\n",
    "# fcn.train_coarse(1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = dsr.next_train_batch(1)\n",
    "images = tb['batch']\n",
    "annotations = tb['annotations']\n",
    "names = tb['names']\n",
    "\n",
    "img_path = os.path.join(TRAINVAL_ROOT_DIR,'VOCdevkit/VOC2011/JPEGImages/{}.jpg'.format(names[0]))\n",
    "img_unnormalized = cv2.imread(img_path)[:,:,::-1]\n",
    "\n",
    "for i in images: img = i\n",
    "for a in annotations: ann = a\n",
    "#img = np.reshape(img, [1, img.shape[0], img.shape[1], img.shape[2]])\n",
    "best_params_ckpt = '.'.join(os.listdir('best_params')[0].split('.')[:-1])\n",
    "segmentation = fcn.infer(img, os.path.join('best_params', best_params_ckpt))\n",
    "\n",
    "def label_matrix_to_image(label_mat, image_file = None):\n",
    "    def convert(label_mod):\n",
    "        # logging.debug('trying to hash {}'.format(label))\n",
    "        label = label_mod[0]\n",
    "        return np.array(dsr.voc_color_map[label], dtype=np.float32)\n",
    "    logging.debug('Label mat shape: {}'.format(label_mat.shape))\n",
    "    label_mat[label_mat == 21] = 255\n",
    "    np.set_printoptions(threshold=np.nan)\n",
    "    # logging.debug('{}'.format(label_mat))\n",
    "    label_mat = np.expand_dims(label_mat, axis=2)\n",
    "    label_mat = np.concatenate([label_mat, np.zeros(label_mat.shape), np.zeros(label_mat.shape)], axis=2)\n",
    "    img_mat = np.apply_along_axis(convert, 2, label_mat)\n",
    "    logging.debug('Converted shape: {}'.format(img_mat.shape))\n",
    "    if image_file is not None:\n",
    "        plt.imsave(fname=image_file, arr=img_mat, format='png')\n",
    "    return img_mat\n",
    "\n",
    "plt.imshow(label_matrix_to_image(segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(label_matrix_to_image(ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_unnormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
