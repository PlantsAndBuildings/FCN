{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from voc_data_reader import VOCDataReader\n",
    "from fcn import FCN\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINVAL_ROOT_DIR = '/root/PASCAL-VOC-Dataset/TrainVal'\n",
    "TEST_ROOT_DIR = '/root/PASCAL-VOC-Dataset/TrainVal'\n",
    "VGG_PARAMS_ROOT_DIR = '/root/tf-fcn/vgg-weights'\n",
    "\n",
    "# fcn = FCN(TRAINVAL_ROOT_DIR, TEST_ROOT_DIR, VGG_PARAMS_ROOT_DIR)\n",
    "dsr = VOCDataReader(TRAINVAL_ROOT_DIR, TEST_ROOT_DIR)\n",
    "\n",
    "tb = dsr.next_train_batch(1)\n",
    "images = tb['batch']\n",
    "names = tb['names']\n",
    "for i in images:\n",
    "    img = i\n",
    "img = np.reshape(img, [1, img.shape[0], img.shape[1], img.shape[2]])\n",
    "img_path = os.path.join(TRAINVAL_ROOT_DIR, 'VOCdevkit/VOC2011/JPEGImages/{}.jpg'.format(names[0]))\n",
    "img_unnormalized = cv2.imread(img_path)[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a small network\n",
    "inp = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "conv_wts = tf.Variable(np.random.randn(3, 3, 3, 10), name = 'conv_wts', dtype=tf.float32)\n",
    "conv1 = tf.nn.conv2d(inp, conv_wts, [1, 1, 1, 1], 'SAME')\n",
    "pool1 = tf.nn.max_pool(conv1, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "upconv_params = tf.Variable(np.random.randn(3, 3, 10, 10), name='upconv_wts', dtype=tf.float32)\n",
    "upconv1 = tf.nn.conv2d_transpose(pool1, upconv_params, output_shape=[1, tf.shape(pool1)[1]*2, tf.shape(pool1)[2]*2, 10], strides=[1,2,2,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 375, 500, 3)\n",
      "(1, 376, 500, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output = sess.run(upconv1, feed_dict = {inp: img})\n",
    "    print(img.shape)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_unnormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
