{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.load('vgg-weights/weights.dat', encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    params = np.reshape(params, (1,))[0]\n",
    "    params.keys()\n",
    "    for key in params.keys():\n",
    "        params[key] = { k.decode('utf-8') : v for k, v in params[key].items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conv5_1', 'fc6', 'conv5_3', 'conv5_2', 'fc8', 'fc7', 'conv4_1', 'conv4_2', 'conv4_3', 'conv3_3', 'conv3_2', 'conv3_1', 'conv1_1', 'conv1_2', 'conv2_2', 'conv2_1'])\n",
      "(4096, 1000)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(params.keys())\n",
    "print(params['fc8']['weights'].shape)\n",
    "print(params['fc8']['biases'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(params['fc8']['weights'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['conv5_1']['biases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the conv2d operation in TF\n",
    "inp = tf.placeholder(dtype=tf.float32, shape=(None, 3, 3, 2))\n",
    "f1 = np.array([[[1,0], [0,1]], [[0,1], [1,0]]], dtype=np.float32)\n",
    "f2 = np.array([[[-1, 0], [0, -1]], [[0, 1], [1, 0]]], dtype=np.float32)\n",
    "f3 = np.array([[[-1, 1], [1, -1]], [[-1, 1], [1, -1]]], dtype=np.float32)\n",
    "f = np.concatenate((np.expand_dims(f1, axis=3), np.expand_dims(f2, axis=3), np.expand_dims(f3, axis=3)), axis=3)\n",
    "print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = tf.Variable(f, name='filters')\n",
    "out = tf.nn.conv2d(inp, filters, [1,1,1,1], 'VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[[1,2,3],[4,5,6],[7,8,9]], [[7,8,9],[4,5,6],[1,2,3]]]])\n",
    "y = np.array([[[[1,7],[2,8],[3,9]],[[4,4],[5,5],[6,6]],[[7,1],[8,2],[9,3]]],\n",
    "              [[[1,7],[2,8],[3,9]],[[4,4],[5,5],[6,6]],[[7,1],[8,2],[9,3]]]])\n",
    "# y = np.reshape(y, (1, 3, 3, 2))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _, out1 = sess.run([inp, out], feed_dict = {inp: y })\n",
    "    print(out1)\n",
    "    print(out1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['conv1_1']['weights'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['conv1_2']['weights'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_label_color_map(N=256, normalized=False):\n",
    "    def bitget(byteval, idx):\n",
    "        return ((byteval & (1 << idx)) != 0)\n",
    "\n",
    "    dtype = 'float32' if normalized else 'uint8'\n",
    "    cmap = np.zeros((N, 3), dtype=dtype)\n",
    "    for i in range(N):\n",
    "        r = g = b = 0\n",
    "        c = i\n",
    "        for j in range(8):\n",
    "            r = r | (bitget(c, 0) << 7-j)\n",
    "            g = g | (bitget(c, 1) << 7-j)\n",
    "            b = b | (bitget(c, 2) << 7-j)\n",
    "            c = c >> 3\n",
    "\n",
    "        cmap[i] = np.array([r, g, b])\n",
    "\n",
    "    cmap = cmap/255 if normalized else cmap\n",
    "    return cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_model(batch_sz):\n",
    "    global params\n",
    "    net = {}\n",
    "\n",
    "    net['input'] = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "    conv1_1_weights = tf.Variable(params['conv1_1']['weights'], name='conv1_1_weights')\n",
    "    conv1_1_biases = tf.Variable(params['conv1_1']['biases'], name='conv1_1_biases')\n",
    "    net['conv1_1'] = tf.nn.bias_add(tf.nn.conv2d(net['input'], conv1_1_weights, [1,1,1,1], 'SAME'), conv1_1_biases)\n",
    "    net['relu1_1'] = tf.nn.relu(net['conv1_1'])\n",
    "\n",
    "    conv1_2_weights = tf.Variable(params['conv1_2']['weights'], name='conv1_2_weights')\n",
    "    conv1_2_biases = tf.Variable(params['conv1_2']['biases'], name='conv1_2_biases')\n",
    "    net['conv1_2'] = tf.nn.bias_add(tf.nn.conv2d(net['relu1_1'], conv1_2_weights, [1,1,1,1], 'SAME'), conv1_2_biases)\n",
    "    net['relu1_2'] = tf.nn.relu(net['conv1_2'])\n",
    "    \n",
    "    net['pool1'] = tf.nn.max_pool(net['relu1_2'], [1,2,2,1], [1,2,2,1], 'SAME')\n",
    "    \n",
    "    conv2_1_weights = tf.Variable(params['conv2_1']['weights'], name='conv2_1_weights')\n",
    "    conv2_1_biases = tf.Variable(params['conv2_1']['biases'], name='conv2_1_biases')\n",
    "    net['conv2_1'] = tf.nn.bias_add(tf.nn.conv2d(net['pool1'], conv2_1_weights, [1,1,1,1], 'SAME'), conv2_1_biases)\n",
    "    net['relu2_1'] = tf.nn.relu(net['conv2_1'])\n",
    "    \n",
    "    conv2_2_weights = tf.Variable(params['conv2_2']['weights'], name='conv2_2_weights')\n",
    "    conv2_2_biases = tf.Variable(params['conv2_2']['biases'], name='conv2_2_biases')\n",
    "    net['conv2_2'] = tf.nn.bias_add(tf.nn.conv2d(net['relu2_1'], conv2_2_weights, [1,1,1,1], 'SAME'), conv2_2_biases)\n",
    "    net['relu2_2'] = tf.nn.relu(net['conv2_2'])\n",
    "    \n",
    "    net['pool2'] = tf.nn.max_pool(net['relu2_2'], [1,2,2,1], [1,2,2,1], 'SAME')\n",
    "    \n",
    "    conv3_1_weights = tf.Variable(params['conv3_1']['weights'], name='conv3_1_weights')\n",
    "    conv3_1_biases = tf.Variable(params['conv3_1']['biases'], name='conv3_1_biases')\n",
    "    net['conv3_1'] = tf.nn.bias_add(tf.nn.conv2d(net['pool2'], conv3_1_weights, [1,1,1,1], 'SAME'), conv3_1_biases)\n",
    "    net['relu3_1'] = tf.nn.relu(net['conv3_1'])\n",
    "    \n",
    "    conv3_2_weights = tf.Variable(params['conv3_2']['weights'], name='conv3_2_weights')\n",
    "    conv3_2_biases = tf.Variable(params['conv3_2']['biases'], name='conv3_2_biases')\n",
    "    net['conv3_2'] = tf.nn.bias_add(tf.nn.conv2d(net['relu3_1'], conv3_2_weights, [1,1,1,1], 'SAME'), conv3_2_biases)\n",
    "    net['relu3_2'] = tf.nn.relu(net['conv3_2'])\n",
    "    \n",
    "    conv3_3_weights = tf.Variable(params['conv3_3']['weights'], name='conv3_3_weights')\n",
    "    conv3_3_biases = tf.Variable(params['conv3_3']['biases'], name='conv3_3_biases')\n",
    "    net['conv3_3'] = tf.nn.bias_add(tf.nn.conv2d(net['relu3_2'], conv3_3_weights, [1,1,1,1], 'SAME'), conv3_3_biases)\n",
    "    net['relu3_3'] = tf.nn.relu(net['conv3_3'])\n",
    "    \n",
    "    net['pool3'] = tf.nn.max_pool(net['relu3_3'], [1,2,2,1], [1,2,2,1], 'SAME')\n",
    "    \n",
    "    conv4_1_weights = tf.Variable(params['conv4_1']['weights'], name='conv4_1_weights')\n",
    "    conv4_1_biases = tf.Variable(params['conv4_1']['biases'], name='conv4_1_biases')\n",
    "    net['conv4_1'] = tf.nn.bias_add(tf.nn.conv2d(net['pool3'], conv4_1_weights, [1,1,1,1], 'SAME'), conv4_1_biases)\n",
    "    net['relu4_1'] = tf.nn.relu(net['conv4_1'])\n",
    "    \n",
    "    conv4_2_weights = tf.Variable(params['conv4_2']['weights'], name='conv4_2_weights')\n",
    "    conv4_2_biases = tf.Variable(params['conv4_2']['biases'], name='conv4_2_biases')\n",
    "    net['conv4_2'] = tf.nn.bias_add(tf.nn.conv2d(net['relu4_1'], conv4_2_weights, [1,1,1,1], 'SAME'), conv4_2_biases)\n",
    "    net['relu4_2'] = tf.nn.relu(net['conv4_2'])\n",
    "    \n",
    "    conv4_3_weights = tf.Variable(params['conv4_3']['weights'], name='conv4_3_weights')\n",
    "    conv4_3_biases = tf.Variable(params['conv4_3']['biases'], name='conv4_3_biases')\n",
    "    net['conv4_3'] = tf.nn.bias_add(tf.nn.conv2d(net['relu4_2'], conv4_3_weights, [1,1,1,1], 'SAME'), conv4_3_biases)\n",
    "    net['relu4_3'] = tf.nn.relu(net['conv4_3'])\n",
    "    \n",
    "    net['pool4'] = tf.nn.max_pool(net['relu4_3'], [1,2,2,1], [1,2,2,1], 'SAME')\n",
    "    \n",
    "    conv5_1_weights = tf.Variable(params['conv5_1']['weights'], name='conv5_1_weights')\n",
    "    conv5_1_biases = tf.Variable(params['conv5_1']['biases'], name='conv5_1_biases')\n",
    "    net['conv5_1'] = tf.nn.bias_add(tf.nn.conv2d(net['pool4'], conv5_1_weights, [1,1,1,1], 'SAME'), conv5_1_biases)\n",
    "    net['relu5_1'] = tf.nn.relu(net['conv5_1'])\n",
    "    \n",
    "    conv5_2_weights = tf.Variable(params['conv5_2']['weights'], name='conv5_2_weights')\n",
    "    conv5_2_biases = tf.Variable(params['conv5_2']['biases'], name='conv5_2_biases')\n",
    "    net['conv5_2'] = tf.nn.bias_add(tf.nn.conv2d(net['relu5_1'], conv5_2_weights, [1,1,1,1], 'SAME'), conv5_2_biases)\n",
    "    net['relu5_2'] = tf.nn.relu(net['conv5_2'])\n",
    "    \n",
    "    conv5_3_weights = tf.Variable(params['conv5_3']['weights'], name='conv5_3_weights')\n",
    "    conv5_3_biases = tf.Variable(params['conv5_3']['biases'], name='conv5_3_biases')\n",
    "    net['conv5_3'] = tf.nn.bias_add(tf.nn.conv2d(net['relu5_2'], conv5_3_weights, [1,1,1,1], 'SAME'), conv5_3_biases)\n",
    "    net['relu5_3'] = tf.nn.relu(net['conv5_3'])\n",
    "    \n",
    "    net['pool5'] = tf.nn.max_pool(net['relu5_3'], [1,2,2,1], [1,2,2,1], 'SAME')\n",
    "    \n",
    "    conv6_weights = tf.Variable(tf.truncated_normal([7, 7, 512, 4096]))\n",
    "    conv6_biases = tf.Variable(tf.zeros([4096,], tf.float32))\n",
    "    net['conv6'] = tf.nn.bias_add(tf.nn.conv2d(net['pool5'], conv6_weights, [1,1,1,1], 'SAME'), conv6_biases)\n",
    "    net['relu6'] = tf.nn.relu(net['conv6'])\n",
    "    \n",
    "    conv7_weights = tf.Variable(tf.truncated_normal([1, 1, 4096, 4096]))\n",
    "    conv7_biases = tf.Variable(tf.zeros([4096,], tf.float32))\n",
    "    net['conv7'] = tf.nn.bias_add(tf.nn.conv2d(net['relu6'], conv7_weights, [1,1,1,1], 'SAME'), conv7_biases)\n",
    "    net['relu7'] = tf.nn.relu(net['conv7'])\n",
    "    \n",
    "    conv8_weights = tf.Variable(tf.truncated_normal([1, 1, 4096, 1000]))\n",
    "    conv8_biases = tf.Variable(tf.zeros([1000,], tf.float32))\n",
    "    net['conv8'] = tf.nn.bias_add(tf.nn.conv2d(net['relu7'], conv8_weights, [1, 1, 1, 1], 'SAME'), conv8_biases)\n",
    "    net['relu8'] = tf.nn.relu(net['conv8'])\n",
    "\n",
    "    upscore2_weights = tf.Variable(tf.truncated_normal([4, 4, 512, 1000]))\n",
    "    upscore2_biases = tf.Variable(tf.zeros([512,], tf.float32))\n",
    "    net['upscore2'] = tf.nn.bias_add(\n",
    "        tf.nn.conv2d_transpose(net['relu8'], upscore2_weights, [batch_sz, 14, 14, 512], strides=[1, 2, 2, 1], padding='SAME'),\n",
    "        upscore2_biases\n",
    "    )\n",
    "    net['fuse_pool4'] = tf.add(net['upscore2'], net['pool4'])\n",
    "    \n",
    "    upscore4_weights = tf.Variable(tf.truncated_normal([4, 4, 256, 512]))\n",
    "    upscore4_biases = tf.Variable(tf.zeros([256,], tf.float32))\n",
    "    net['upscore4'] = tf.nn.bias_add(\n",
    "        tf.nn.conv2d_transpose(net['fuse_pool4'], upscore4_weights, [batch_sz, 28, 28, 256], strides=[1, 2, 2, 1], padding='SAME'),\n",
    "        upscore4_biases\n",
    "    )\n",
    "    net['fuse_pool3'] = tf.add(net['upscore4'], net['pool3'])\n",
    "    \n",
    "    upscore32_weights = tf.Variable(tf.truncated_normal([4, 4, 21, 256]))\n",
    "    upscore32_biases = tf.Variable(tf.zeros([21,], tf.float32))\n",
    "    net['upscore32'] = tf.nn.bias_add(\n",
    "        tf.nn.conv2d_transpose(net['fuse_pool3'], upscore32_weights, [batch_sz, 224, 224, 21], strides=[1, 8, 8, 1], padding='SAME'),\n",
    "        upscore32_biases\n",
    "    )\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = vgg16_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net['conv1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    op, inp = sess.run([net['upscore32'], net['input']], feed_dict = {net['input']: np.array([cv2.resize(cv2.imread('2008_004512.jpg'), (224, 224))])})\n",
    "    print(op.shape)\n",
    "    print(inp.shape)\n",
    "    if op.shape[3] == 64:\n",
    "        plt.figure(figsize=(20,20))\n",
    "    elif op.shape[3] == 128:\n",
    "        plt.figure(figsize=(40,20))\n",
    "    elif op.shape[3] == 256:\n",
    "        plt.figure(figsize=(13,13))\n",
    "    elif op.shape[3] == 512:\n",
    "        plt.figure(figsize=(20,10))    \n",
    "    for fidx in range(op.shape[3]):\n",
    "        if op.shape[3] == 64:\n",
    "            plt.subplot(8, 8, fidx+1)\n",
    "        elif op.shape[3] == 128:\n",
    "            plt.subplot(16, 8, fidx+1)\n",
    "        elif op.shape[3] == 256:\n",
    "            plt.subplot(16, 16, fidx+1)\n",
    "        elif op.shape[3] == 512:\n",
    "            plt.subplot(32, 16, fidx+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(op[0][:,:,fidx])\n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(op[0][:,:,0])\n",
    "    plt.imsave(fname='2008_004512_output.png', arr=op[0][:,:,0], format='png')\n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(cv2.imread('2008_004512.jpg')[:,:,::-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(params['conv5_3']['weights'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
